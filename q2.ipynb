{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e60109dd740a1c92feb05d30890eaf1a",
     "grade": false,
     "grade_id": "cell-c4ab9a740c51dfd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img align=\"center\" src=\"images/course.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "638f6a5696206b7c42fd1c94bc5ea241",
     "grade": false,
     "grade_id": "cell-3c6401138ee3087d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 16720 (B)  3D Reconstruction - Assignment 5 - q2\n",
    "    Instructor: Kris                          TAs: Arka, Jinkun, Rawal, Rohan, Sheng-Yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c81b61a2425b77aff4450094e1c2de03",
     "grade": false,
     "grade_id": "cell-951f7cf42448155b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions for this assignment. DO NOT MODIFY!!!\n",
    "\"\"\"\n",
    "Helper functions.\n",
    "\n",
    "Written by Chen Kong, 2018.\n",
    "Modified by Zhengyi (Zen) Luo, 2021\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy\n",
    "import nbimporter\n",
    "from q1 import eightpoint, camera2, _epipoles, toHomogenous\n",
    "\n",
    "def epipolarMatchGUI(I1, I2, F):\n",
    "    matplotlib.use('TkAgg')\n",
    "    e1, e2 = _epipoles(F)\n",
    "\n",
    "    sy, sx, _ = I2.shape\n",
    "\n",
    "    f, [ax1, ax2] = plt.subplots(1, 2, figsize=(12, 9))\n",
    "    ax1.imshow(I1)\n",
    "    ax1.set_title('Select a point in this image')\n",
    "    ax1.set_axis_off()\n",
    "    ax2.imshow(I2)\n",
    "    ax2.set_title('Verify that the corresponding point \\n is on the epipolar line in this image')\n",
    "    ax2.set_axis_off()\n",
    "\n",
    "    while True:\n",
    "        plt.sca(ax1)\n",
    "        x, y = plt.ginput(1, mouse_stop=2)[0]\n",
    "\n",
    "        xc = int(x)\n",
    "        yc = int(y)\n",
    "        v = np.array([xc, yc, 1])\n",
    "        l = F.dot(v)\n",
    "        s = np.sqrt(l[0]**2+l[1]**2)\n",
    "\n",
    "        if s==0:\n",
    "            error('Zero line vector in displayEpipolar')\n",
    "\n",
    "        l = l/s;\n",
    "\n",
    "        if l[0] != 0:\n",
    "            ye = sy-1\n",
    "            ys = 0\n",
    "            xe = -(l[1] * ye + l[2])/l[0]\n",
    "            xs = -(l[1] * ys + l[2])/l[0]\n",
    "        else:\n",
    "            xe = sx-1\n",
    "            xs = 0\n",
    "            ye = -(l[0] * xe + l[2])/l[1]\n",
    "            ys = -(l[0] * xs + l[2])/l[1]\n",
    "\n",
    "        # plt.plot(x,y, '*', 'MarkerSize', 6, 'LineWidth', 2);\n",
    "        ax1.plot(x, y, '*', markersize=6, linewidth=2)\n",
    "        ax2.plot([xs, xe], [ys, ye], linewidth=2)\n",
    "\n",
    "        # draw points\n",
    "        x2, y2 = epipolarCorrespondence(I1, I2, F, xc, yc)\n",
    "        ax2.plot(x2, y2, 'ro', markersize=8, linewidth=2)\n",
    "        plt.draw()\n",
    "\n",
    "def plot_3D(P):\n",
    "    matplotlib.use('TkAgg')\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(P[:,0], P[:,1], P[:,2])\n",
    "    while True:\n",
    "        x, y = plt.ginput(1, mouse_stop=2)[0]\n",
    "        plt.draw()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef2fb02cee64bf9716a4cf20a24ec3e6",
     "grade": false,
     "grade_id": "cell-8cbbfcc0342ed1ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q2: Metric Reconstruction\n",
    "You will compute the camera matrices and triangulate the 2D points to obtain the 3D scene structure. To obtain the Euclidean scene structure, first convert the fundamental matrix $\\textbf{F}$ to an essential matrix $\\textbf{E}$. Examine the lecture notes and the textbook to find out how to do this when the internal camera calibration matrices $\\textbf{K}_1$ and $\\textbf{K}_2$ are known; these are provided in `data/intrinsics.npz`.\n",
    "\n",
    "### Q2.1: Essential Matrix (5 pt implementation)\n",
    "Write a function to compute the essential matrix $\\textbf{E}$ given $\\textbf{F}$, $\\textbf{K}_1$ and $\\textbf{K}_2$ with the signature:\n",
    "\n",
    "```\n",
    "E = essentialMatrix(F, K1, K2)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac09d93d25047c98352b2ee7d86bf1af",
     "grade": false,
     "grade_id": "cell-75539a0c38616db4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def essentialMatrix(F, K1, K2):\n",
    "    '''\n",
    "    Q1.1: Compute the essential matrix E given the fundamental matrix and camera intrinsics\n",
    "        Input:  F, fundamental matrix\n",
    "                K1, internal camera calibration matrix of camera 1\n",
    "                K2, internal camera calibration matrix of camera 2\n",
    "        Output: E, the essential matrix\n",
    "    '''\n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    E = np.dot(K1.T, np.dot(F, K2))\n",
    "    return E\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d525d660703f30c72575d4d386aa455f",
     "grade": false,
     "grade_id": "cell-a3a93f3bfd0a89f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -0.5069   68.6543 -371.9615]\n",
      " [  29.7107   -1.5472    9.6823]\n",
      " [ 372.9911    2.9855    0.1504]]\n"
     ]
    }
   ],
   "source": [
    "# Printing out the essential matrix\n",
    "np.set_printoptions(precision=4, suppress=1)\n",
    "correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "K1, K2 = intrinsics['K1'], intrinsics['K2']\n",
    "pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "im1 = plt.imread('data/im1.png')\n",
    "im2 = plt.imread('data/im2.png')\n",
    "\n",
    "F = eightpoint(pts1, pts2, M=np.max([*im1.shape, *im2.shape]))\n",
    "E = essentialMatrix(F, K1, K2)\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7cd36d551bf89de67c9b8f5d8b61703b",
     "grade": true,
     "grade_id": "q2_1_a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Simple Tests to verify your implmentation:\n",
    "correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "K1, K2 = intrinsics['K1'], intrinsics['K2']\n",
    "pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "F = eightpoint(pts1, pts2, M=np.max([*im1.shape, *im2.shape]))\n",
    "E = essentialMatrix(F, K1, K2)\n",
    "assert(np.linalg.matrix_rank(E) == 2)\n",
    "\n",
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 Triangulation and find M2 (5 pt writeup, 20 pt implementation)\n",
    "Given an essential matrix, it is possible to retrieve the projective camera matrices $\\textbf{M}_1$ and $\\textbf{M}_2$ from it.  Assuming $\\textbf{M}_1$ is fixed at $[\\textbf{I},0]$, $\\textbf{M}_2$ can be retrieved up to a scale and four-fold rotation ambiguity. For details on recovering $\\textbf{M}_2$, see section 7.2 in Szeliski. We have provided you with the function `camera2` to recover as the four possible $\\textbf{M}_2$ matrices given $\\textbf{E}$.\n",
    "\n",
    "**Note:** The $\\textbf{M}_1$ and $\\textbf{M}_2$ here are projection matrices of the form:\n",
    "$\\textbf{M}_1 = \\begin{bmatrix}\n",
    "\\textbf{I} | 0\n",
    "\\end{bmatrix} $ and $\\textbf{M}_2 = \\begin{bmatrix}\n",
    "\\textbf{R} | \\textbf{t}\n",
    "\\end{bmatrix} $.\n",
    "\n",
    "Using the above, write a function to triangulate a set of 2D coordinates in the image to a set of 3D\n",
    "points with the signature:\n",
    "```\n",
    "    [w, err] = triangulate(C1, pts1, C2, pts2)\n",
    "```\n",
    "where `pts1` and `pts2` are the $N \\times 2$ matrices with the 2D image coordinates and `w` is an $N \\times 3$ matrix with the corresponding 3D points per row.  `C1` and `C2` are the $3 \\times 4$ camera matrices. Remember that you will need to multiply the given intrinsics matrices with your solution for the canonical camera matrices to obtain the final camera matrices. Various methods exist for triangulation - probably the most familiar for you is based on least squares (see Szeliski Chapter 7 if you want to learn about other methods):\n",
    "\n",
    "For each point $i$, we want to solve for 3D coordinates $\\textbf{w}_i = \\begin{bmatrix}x_i, y_i, z_i\\end{bmatrix}^T$, such that when they are projected back to the two images, they are close to the original 2D points. To project the 3D coordinates back to 2D images, we first write $\\textbf{w}_i$ in homogeneous coordinates, and compute $\\mathbf{C}_1 \\tilde{\\textbf{w}_i}$ and $\\mathbf{C}_2 \\tilde{\\textbf{w}_i}$ to obtain the 2D homogeneous coordinates projected to camera $1$ and camera $2$, respectively.\n",
    "\n",
    "For each point $i$, we can write this problem in the following form:\n",
    "\\begin{align}\n",
    "\\mathbf{A}_i w_i = 0\n",
    "\\end{align}\n",
    "where $\\mathbf{A}_i$ is a $4\\times 4$ matrix, and $\\tilde{\\textbf{w}_i}$ is a $4\\times 1$ vector of the 3D coordinates in the homogeneous form. Then, you can obtain the homogeneous least-squares solution (discussed in class) to solve for each $\\textbf{w}_i$.\n",
    "\n",
    "Once you have implemented triangulation, you can check the performance by looking at the reprojection error:  $$ \\texttt{err} = \\sum_i ||\\textbf{x}_{1i} - \\widehat{\\textbf{x}_{1i}}||^2 + ||\\textbf{x}_{2i} - \\widehat{\\textbf{x}_{2i}}||^2$$\n",
    "where $\\widehat{\\textbf{x}_{1i}} = Proj(\\mathbf{C}_1, \\textbf{w}_i)$ and $\\widehat{\\textbf{x}_{2i}} = Proj(\\mathbf{C}_2, \\textbf{w}_i)$.\n",
    "\n",
    "\n",
    "**Note:** `C1` and `C2` here are projection matrices of the form:\n",
    "$\\mathbf{C}_1 = \\mathbf{K}_1\\mathbf{M}_1 = \\mathbf{K}_1 \\begin{bmatrix}\n",
    "\\textbf{I} | 0\n",
    "\\end{bmatrix} $ and $\\mathbf{C}_2 =  \\mathbf{K}_2\\mathbf{M}_2 = \\mathbf{K}_2 \\begin{bmatrix}\n",
    "\\textbf{R} | \\textbf{t}\n",
    "\\end{bmatrix}$.\n",
    "\n",
    "Write a function, \n",
    "```\n",
    "    [M2, C2, P] = findM2()\n",
    "```\n",
    "to load the correspondences and use triangulation to find the M2, C2, and P that minimize the reprojection error. \n",
    "\n",
    "<span style='color:red'>**Output:**</span> In your write-up: Write down the expression for the matrix $\\mathbf{A}_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdb9dd4c5b8428762b8d535d0d4b2f5b",
     "grade": false,
     "grade_id": "cell-af5ab5f8a3142145",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def triangulate(C1, pts1, C2, pts2):\n",
    "    '''\n",
    "    Q2.2: Triangulate a set of 2D coordinates in the image to a set of 3D points.\n",
    "        Input:  C1, the 3x4 camera matrix\n",
    "                pts1, the Nx2 matrix with the 2D image coordinates per row\n",
    "                C2, the 3x4 camera matrix\n",
    "                pts2, the Nx2 matrix with the 2D image coordinates per row\n",
    "        Output: P, the Nx3 matrix with the corresponding 3D points per row\n",
    "                err, the reprojection error.\n",
    "    \n",
    "    ***\n",
    "    Hints:\n",
    "    (1) For every input point, form A using the corresponding points from pts1 & pts2 and C1 & C2\n",
    "    (2) Solve for the least square solution using np.linalg.svd\n",
    "    (3) Calculate the reprojection error using the calculated 3D points and C1 & C2 (do not forget to convert from \n",
    "        homogeneous coordinates to non-homogeneous ones)\n",
    "    (4) Keep track of the 3D points and projection error, and continue to next point \n",
    "    (5) You do not need to follow the exact procedure above. \n",
    "    '''\n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    p1 = C1[0]\n",
    "    p2 = C1[1]\n",
    "    p3 = C1[2]\n",
    "\n",
    "    p1t = C2[0]\n",
    "    p2t = C2[1]\n",
    "    p3t = C2[2]\n",
    "\n",
    "    A = []\n",
    "    P = []\n",
    "    err = np.zeros((len(pts1), )) \n",
    "    for i in range(len(pts1)):\n",
    "        x1, y1 = pts1[i]\n",
    "        x2, y2 = pts2[i]\n",
    "\n",
    "        A = np.array(\n",
    "            [\n",
    "                [y1*p3 - p2],\n",
    "                [p1 - x1*p3],\n",
    "                [y2*p3t - p2t],\n",
    "                [p1t - x2*p3t]\n",
    "            ]\n",
    "        ).squeeze()\n",
    "\n",
    "\n",
    "        U, S, V = np.linalg.svd(A)\n",
    "        val = V[-1]\n",
    "        val /= val[3]\n",
    "\n",
    "        if val[2] < 0:\n",
    "            return np.array([]), np.inf\n",
    "\n",
    "        proj1 = np.dot(C1, val)\n",
    "        proj1 /= proj1[2]\n",
    "\n",
    "        proj2 = np.dot(C2, val)\n",
    "        proj2 /= proj2[2]\n",
    "        err[i] =np.linalg.norm((np.array([x1, y1, 1]) - proj1 )) ** 2  +\\\n",
    "              np.linalg.norm((np.array([x2, y2, 1]) - proj2)) ** 2\n",
    "\n",
    "        P.append(val)\n",
    "        \n",
    "\n",
    "    P = np.array(P)\n",
    "\n",
    "    err = np.sum(err)\n",
    "\n",
    "    return P, err\n",
    "    \n",
    "\n",
    "def find_M2(F, pts1, pts2, intrinsics):\n",
    "    '''\n",
    "    Q2.2: Function to find the camera2's projective matrix given correspondences\n",
    "        Input:  F, the pre-computed fundamental matrix\n",
    "                pts1, the Nx2 matrix with the 2D image coordinates per row\n",
    "                pts2, the Nx2 matrix with the 2D image coordinates per row\n",
    "                intrinsics, the intrinsics of the cameras, load from the .npz file\n",
    "        Output: [M2, C2, P] the computed M2 (3x4) camera projective matrix, C2 (3x4) K2 * M2, and the 3D points P (Nx3)\n",
    "    \n",
    "    ***\n",
    "    Hints:\n",
    "    (1) Loop through the 'M2s' and use triangulate to calculate the 3D points and projection error. Keep track \n",
    "        of the projection error through best_error and retain the best one. \n",
    "    (2) Remember to take a look at camera2 to see how to correctly reterive the M2 matrix from 'M2s'. \n",
    "\n",
    "    '''\n",
    "    K1 = intrinsics[\"K1\"]\n",
    "    K2 = intrinsics[\"K2\"]\n",
    "    E = essentialMatrix(F, K1, K2)\n",
    "    M1 = np.hstack((np.identity(3), np.zeros(3)[:,np.newaxis]))\n",
    "    C1 = K1.dot(M1)\n",
    "    M2s = camera2(E)\n",
    "    best_error = np.finfo('float').max\n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    M_final, C_final, P_final = None, None, None\n",
    "    for i in range(M2s.shape[-1]):\n",
    "        M2 = M2s[:,:,i]\n",
    "        det = np.linalg.det(M2[:3, :3])\n",
    "        # print(det)\n",
    "        if abs(det - 1) > 1e-12:\n",
    "            print(\"Det is not 1 | Skipping\", i, 'Det = ', det, abs(det - 1) , abs(det - 1) < 1e-5)\n",
    "            continue\n",
    "        \n",
    "        C2 = K2.dot(M2)    \n",
    "        P, err = triangulate(C1, pts1, C2, pts2)\n",
    "        print(\"Error at\", i, \"ERR\", err)\n",
    "        if err < best_error:\n",
    "            M_final = M2\n",
    "            C_final = C2\n",
    "            P_final = P\n",
    "            best_error = err\n",
    "\n",
    "\n",
    "    \n",
    "    print(f\"Best Error {best_error}\")\n",
    "    P_final = P_final[:, :3]\n",
    "    return M_final, C_final, P_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74b4f00e6f91dfec1202922246eb0dc3",
     "grade": false,
     "grade_id": "cell-e702426864c5ae3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at 0 ERR 351.8979668567848\n",
      "Error at 1 ERR 351.8979668567848\n",
      "Error at 2 ERR 351.89788927211043\n",
      "Error at 3 ERR 351.89788927211043\n",
      "Best Error 351.89788927211043\n",
      "M2: [[-0.9998  0.0176  0.0034 -0.026 ]\n",
      " [ 0.0179  0.9945  0.1029 -1.    ]\n",
      " [-0.0016  0.1029 -0.9947  0.0796]]\n",
      "C2 [[-1520.6345    57.9266  -295.5144   -15.4571]\n",
      " [   26.9152  1542.965    -88.6018 -1506.2442]\n",
      " [   -0.0016     0.1029    -0.9947     0.0796]]\n"
     ]
    }
   ],
   "source": [
    "# Running the find_M2 funciton:\n",
    "np.set_printoptions(precision=4, suppress=1)\n",
    "correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "K1, K2 = intrinsics['K1'], intrinsics['K2']\n",
    "pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "im1, im2 = plt.imread('data/im1.png'), plt.imread('data/im2.png')\n",
    "\n",
    "F = eightpoint(pts1, pts2, M = np.max([*im1.shape, *im2.shape]))\n",
    "M2, C2, P = find_M2(F, pts1, pts2, intrinsics)\n",
    "print(f\"M2: {M2}\")\n",
    "print(f\"C2 {C2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1518363398a483da0fcb0f037fc0625",
     "grade": true,
     "grade_id": "q2_2_a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351.89788927211043\n"
     ]
    }
   ],
   "source": [
    "# Simple Tests to verify your implmentation:\n",
    "M1 = np.hstack((np.identity(3), np.zeros(3)[:,np.newaxis]))\n",
    "C1 = K1.dot(M1)\n",
    "C2 = K2.dot(M2)\n",
    "P_test, err = triangulate(C1, pts1, C2, pts2)\n",
    "print(err)\n",
    "assert(err < 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61222c3806992202593591f185dd999a",
     "grade": true,
     "grade_id": "q2_2_b",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3 Epipolar Correspondence (5 pt writeup, 10 pt implementation)\n",
    "\n",
    "You will now create a 3D visualization of the temple images. By treating our\n",
    "two images as a stereo-pair, we can triangulate corresponding points in each\n",
    "image, and render their 3D locations.\n",
    "\n",
    "\n",
    "\n",
    "Implement a function with the\n",
    "signature:\n",
    "```\n",
    "    [x2, y2] = epipolarCorrespondence(im1, im2, F, x1, y1)\n",
    "```\n",
    "\n",
    "This function takes in the $x$ and $y$ coordinates of a pixel on `im1` and your fundamental matrix $\\textbf{F}$, and returns the coordinates of the pixel on `im2` which correspond to the input point. The match is obtained by computing the similarity of a small window around the $(x_1, y_1)$ coordinates in `im1` to various windows around possible matches in the `im2` and returning the closest.\n",
    "\n",
    "Instead of searching for the matching point at every possible location in `im2`, we can use $\\textbf{F}$ and simply search over the set of pixels that lie along the epipolar line (recall that the epipolar line passes through a single\n",
    "point in `im2`  which corresponds to the point $(x_1, y_1)$ in `im1`!.\n",
    "\n",
    "There are various possible ways to compute the window similarity. For this assignment, simple methods such as the Euclidean or Manhattan distances between the intensity of the pixels should suffice.  See Szeliski Chapter 11, on stereo matching, for a brief overview of these and other methods.\n",
    "\n",
    "\n",
    "**Implementation hints:**\n",
    "- Experiments with various window sizes.\n",
    "- It may help to use a Gaussian weighting of the window, so that the center\n",
    "  has greater influence than the periphery.\n",
    "- Since the two images only differ by a small amount, it might be beneficial to consider matches for which the distance from $(x_1, y_1)$ to $(x_2, y_2)$ is small.\n",
    "\n",
    "To help you test your `epipolarCorrespondence`, we have included a helper function `epipolarMatchGUI`, which takes in two images the fundamental matrix.\n",
    "\n",
    "This GUI allows you to click on a point in `im1`, and will use your function to display the corresponding point in `im2`. See:\n",
    "\n",
    "<img align=\"center\" src=\"images/q3gui_disp_arun.png\" width=\"800\">\n",
    "\n",
    "It's not necessary for your matcher to get **every** possible point right, but it should get easy points (such as those with distinctive corner-like windows).\n",
    "\n",
    "It should also be good enough to render an intelligible representation in the next question.\n",
    "\n",
    "<span style='color:red'>**Output:**</span> In your write-up, include a screenshot of `epipolarMatchGUI`\n",
    "with some detected correspondences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96ecb83014e86c094c26f57f81c1b958",
     "grade": false,
     "grade_id": "cell-5675d5028163b272",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def epipolarCorrespondence(im1, im2, F, x1, y1):\n",
    "    '''\n",
    "    Q2.3 3D visualization of the temple images.\n",
    "        Input:  im1, the first image\n",
    "                im2, the second image\n",
    "                F, the fundamental matrix\n",
    "                x1, x-coordinates of a pixel on im1\n",
    "                y1, y-coordinates of a pixel on im1\n",
    "        Output: x2, x-coordinates of the pixel on im2\n",
    "                y2, y-coordinates of the pixel on im2\n",
    "    \n",
    "    ***\n",
    "    Hints:\n",
    "    (1) Given input [x1, x2], use the fundamental matrix to recover the corresponding epipolar line on image2\n",
    "    (2) Search along this line to check nearby pixel intensity (you can define a search window) to \n",
    "        find the best matches\n",
    "    (3) Use guassian weighting to weight the pixel simlairty\n",
    "    \n",
    "    '''\n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    winsize = 15\n",
    "    hwinsize = winsize//2\n",
    "\n",
    "    lt = F.dot(np.array([x1, y1, 1]).T)\n",
    "    \n",
    "    lam = lambda y : int((-lt[1]/lt[0]) * y - lt[2]/lt[0])\n",
    "    starty = hwinsize\n",
    "    endy = im2.shape[0] - hwinsize - 1\n",
    "    minsad = np.inf\n",
    "    \n",
    "    patch = im1[y1 - hwinsize : y1 + hwinsize + 1,  x1 - hwinsize: x1 + hwinsize + 1]\n",
    "    for y in range(starty, endy):\n",
    "        x = lam(y)\n",
    "        if x < hwinsize or x > im2.shape[1] - hwinsize - 1:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            sad = np.sum(\n",
    "                np.abs(\n",
    "                    patch -\n",
    "                    im2[y - hwinsize: y + hwinsize + 1,  x - hwinsize: x + hwinsize + 1]\n",
    "                )\n",
    "            )\n",
    "        except:\n",
    "            print(x, y)\n",
    "            print(im2[y - hwinsize: y + hwinsize + 1,  x - hwinsize: x + hwinsize + 1].shape)\n",
    "            assert False\n",
    "        if sad < minsad:\n",
    "            minsad = sad\n",
    "            x2, y2 = x, y\n",
    "\n",
    "\n",
    "    return x2, y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d65d493042e5e9fbcbd7d43a1e7d8bc4",
     "grade": false,
     "grade_id": "cell-8dc6e1c9f5d0af41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualization:\n",
    "np.set_printoptions(precision=4, suppress=1)\n",
    "correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "K1, K2 = intrinsics['K1'], intrinsics['K2']\n",
    "pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "im1, im2 = plt.imread('data/im1.png'), plt.imread('data/im2.png')\n",
    "\n",
    "F = eightpoint(pts1, pts2, M=np.max([*im1.shape, *im2.shape]))\n",
    "# epipolarMatchGUI(im1, im2, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adabb209a157cc63a12a19c025da9fe2",
     "grade": true,
     "grade_id": "q2_3_a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Simple Tests to verify your implmentation:\n",
    "correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "K1, K2 = intrinsics['K1'], intrinsics['K2']\n",
    "pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "im1, im2 = plt.imread('data/im1.png'), plt.imread('data/im2.png')\n",
    "F = eightpoint(pts1, pts2, M=np.max([*im1.shape, *im2.shape]))\n",
    "x2, y2 = epipolarCorrespondence(im1, im2, F, 119, 217)\n",
    "\n",
    "assert(np.linalg.norm(np.array([x2, y2]) - np.array([118, 181])) < 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e4930df209e0a35044969dd369bc9b9",
     "grade": true,
     "grade_id": "q2_3_b",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a2e7990f2939e59119f656de861837b3",
     "grade": false,
     "grade_id": "cell-83938fccb883a2d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q2.4 3D Visualization (3pt writeup, 7 pt implementation) \n",
    "\n",
    "Included in this homework  is a file data/templeCoords.npz which contains 288 hand-selected points from `im1` saved in the variables `x1` and `y1`.\n",
    "\n",
    "Now, we can determine the 3D location of these point correspondences using the `triangulate` function. These 3D point locations can then plotted using the `Matplotlib` package (we have provided the necessary starter code for visualization). An example is shown here: \n",
    "\n",
    "\n",
    "|![alt](images/q3a.png) |![alt](images/q3b.png)|\n",
    "|-|-|\n",
    "|![alt](images/q3b.png) |![alt](images/q3c.png)|\n",
    "|-|-|\n",
    "\n",
    "\n",
    "<span style='color:red'>**Output:**</span> In your write-up: Take a few screenshots of the 3D visualization\n",
    "so that the outline of the temple is clearly visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9bfb9cfbd2dcb325127469c72902ee9",
     "grade": false,
     "grade_id": "cell-640b94de9f802a27",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute3D_pts(pts1, intrinsics, F, im1, im2):\n",
    "    '''\n",
    "    Q2.4: Finding the 3D position of given points based on epipolar correspondence and triangulation\n",
    "        Input:  pts1, chosen points from im1\n",
    "                intrinsics, the intrinsics dictionary for calling epipolarCorrespondence\n",
    "                F, the fundamental matrix\n",
    "                im1, the first image\n",
    "                im2, the second image\n",
    "        Output: P (Nx3) the recovered 3D points\n",
    "    \n",
    "    ***\n",
    "    Hints:\n",
    "    (1) Use epipolarCorrespondence to find the corresponding point for [x1 y1] (find [x2, y2])\n",
    "    (2) Now you have a set of corresponding points [x1, y1] and [x2, y2], you can compute the M2\n",
    "        matrix and use triangulate to find the 3D points. \n",
    "    (3) Use the function findM2 to find the 3D points P (do not recalculate fundamental matrices)\n",
    "    (4) As a reference, our solution's bet error is around ~2000 on the 3D points. \n",
    "    '''\n",
    "    x1s_temple, y1s_temple = pts1[:, 0], pts1[:, 1]\n",
    "    P = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for i in range(len(x1s_temple)):\n",
    "        x1, y1 = x1s_temple[i], y1s_temple[i]\n",
    "        x2, y2 = epipolarCorrespondence(im1, im2, F, x1, y1)\n",
    "        pts1.append([x1, y1])\n",
    "        pts2.append([x2, y2])\n",
    "\n",
    "    M2, C2, P = find_M2(F, np.array(pts1), np.array(pts2), intrinsics)\n",
    "    print(P.shape)\n",
    "    return P[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ac74f18038335e30a411bb35f336738",
     "grade": false,
     "grade_id": "cell-0f4232aad2b21f9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# # Visualization:\n",
    "# correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "# intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "# templeCoords = np.load(\"data/templeCoords.npz\")\n",
    "# pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "\n",
    "# im1, im2 = plt.imread('data/im1.png'), plt.imread('data/im2.png')\n",
    "\n",
    "# F = eightpoint(pts1, pts2, M=np.max([*im1.shape, *im2.shape]))\n",
    "\n",
    "# pts1 = np.hstack([templeCoords[\"x1\"], templeCoords[\"y1\"]])\n",
    "# print(pts1.shape)\n",
    "# P = compute3D_pts(pts1, intrinsics, F, im1, im2)\n",
    "\n",
    "# plot_3D(P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 2)\n",
      "0 0.3161764705882353\n",
      "0 0.40441176470588236\n",
      "10 0.4117647058823529\n",
      "23 0.45588235294117646\n",
      "35 0.4632352941176471\n",
      "41 0.5294117647058824\n",
      "[[ 0.     -0.     -0.004 ]\n",
      " [ 0.      0.     -0.0094]\n",
      " [ 0.0002  0.0089  1.    ]]\n",
      "Error at 0 ERR 6395.130994410373\n",
      "Error at 1 ERR 6395.130994410373\n",
      "Error at 2 ERR 6393.432544028332\n",
      "Error at 3 ERR 6393.432544028332\n",
      "Best Error 6393.432544028332\n",
      "(136, 3)\n"
     ]
    }
   ],
   "source": [
    "# Visualization:\n",
    "import cv2\n",
    "from q1 import sevenpoint, calc_epi_error\n",
    "correspondence = np.load('data/some_corresp.npz') # Loading correspondences\n",
    "intrinsics = np.load('data/intrinsics.npz') # Loading the intrinscis of the camera\n",
    "templeCoords = np.load(\"data/templeCoords.npz\")\n",
    "pts1, pts2 = correspondence['pts1'], correspondence['pts2']\n",
    "\n",
    "im1, im2 = cv2.imread('images/dinoSR0001.png'),  cv2.imread('images/dinoSR0002.png')\n",
    "query_img = im1\n",
    "train_img = im2\n",
    "# plot_3D(P)\n",
    "query_img_bw = cv2.cvtColor(query_img,cv2.COLOR_BGR2GRAY)\n",
    "train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "orb = cv2.ORB_create()\n",
    "queryKeypoints, queryDescriptors = orb.detectAndCompute(query_img_bw,None)\n",
    "trainKeypoints, trainDescriptors = orb.detectAndCompute(train_img_bw,None)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = matcher.match(queryDescriptors,trainDescriptors)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "for match in matches:\n",
    "  p1 = queryKeypoints[match.queryIdx].pt\n",
    "  p2 = trainKeypoints[match.trainIdx].pt\n",
    "  pts1.append(np.array(p1).astype(int))\n",
    "  pts2.append(np.array(p2).astype(int))\n",
    "\n",
    "pts1 = np.array(pts1)\n",
    "pts2 = np.array(pts2)\n",
    "\n",
    "print(pts2.shape)\n",
    "def ransacF(pts1, pts2, M):\n",
    "    '''\n",
    "    Q3.1: RANSAC method.\n",
    "        Input:  pts1, Nx2 Matrix\n",
    "                pts2, Nx2 Matrix\n",
    "                M, a scaler parameter\n",
    "        Output: F, the fundamental matrix\n",
    "                inlier_curr, Nx1 bool vector set to true for inliers\n",
    "    ***\n",
    "    Hints:\n",
    "    (1) You can use the calc_epi_error from q1 with threshold to calcualte inliers. Tune the threshold based on \n",
    "        the results/expected number of inliners. You can also define your own metric. \n",
    "    (2) Use the seven point alogrithm to estimate the fundamental matrix as done in q1\n",
    "    (3) Choose the resulting F that has the most number of inliers\n",
    "    (4) You can increase the nIters to bigger/smaller values\n",
    "        \n",
    "    '''\n",
    "    N = pts1.shape[0]\n",
    "    pts1_homo, pts2_homo = toHomogenous(pts1), toHomogenous(pts2)\n",
    "    threshold = 10\n",
    "    max_iteration = 100\n",
    "    best_inlier = 0\n",
    "    inlier_curr = 0\n",
    "\n",
    "    inliers = np.zeros((len(pts1), ), dtype = bool)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(max_iteration):\n",
    "        choices = np.random.choice(len(pts1), size=7, replace=False)\n",
    "        farray = sevenpoint(pts1[choices], pts2[choices], M)\n",
    "        for F in farray:\n",
    "            errors = calc_epi_error(pts1_homo, pts2_homo, F)\n",
    "            nInliers = np.sum(errors < threshold)\n",
    "            if inlier_curr < nInliers:\n",
    "                print(i, nInliers/len(errors)) \n",
    "                inlier_curr = nInliers\n",
    "                inliers[errors < threshold] = True\n",
    "                inliers[errors > threshold] = False\n",
    "            \n",
    "\n",
    "    return F, inliers\n",
    "\n",
    "F, inliers = ransacF(pts1, pts2, M=np.max([*im1.shape, *im2.shape]))\n",
    "print(F)\n",
    "print(inliers.sum())\n",
    "\n",
    "# pts1 = np.hstack([templeCoords[\"x1\"], templeCoords[\"y1\"]])\n",
    "# print(pts1.shape)\n",
    "P = compute3D_pts(pts1, intrinsics, F, im1, im2)\n",
    "\n",
    "# plot_3D(P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mg:\\My Drive\\Acads\\Computer Vision\\Assignments\\hw5\\q2.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Acads/Computer%20Vision/Assignments/hw5/q2.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plot_3D(P)\n",
      "\u001b[1;32mg:\\My Drive\\Acads\\Computer Vision\\Assignments\\hw5\\q2.ipynb Cell 23\u001b[0m in \u001b[0;36mplot_3D\u001b[1;34m(P)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Acads/Computer%20Vision/Assignments/hw5/q2.ipynb#X34sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m ax\u001b[39m.\u001b[39mscatter(P[:,\u001b[39m0\u001b[39m], P[:,\u001b[39m1\u001b[39m], P[:,\u001b[39m2\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Acads/Computer%20Vision/Assignments/hw5/q2.ipynb#X34sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Acads/Computer%20Vision/Assignments/hw5/q2.ipynb#X34sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     x, y \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39;49mginput(\u001b[39m1\u001b[39;49m, mouse_stop\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Acads/Computer%20Vision/Assignments/hw5/q2.ipynb#X34sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     plt\u001b[39m.\u001b[39mdraw()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "plot_3D(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aab0c030a892753ba59e210b4f193d36",
     "grade": true,
     "grade_id": "q2_4_a",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('lpy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "368.111px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "8a5f83665e2d1a2721f1b9b52eb576adbf12a04fc14c75407e99aa6496dd8113"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
